{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba826fe",
   "metadata": {
    "papermill": {
     "duration": 0.014912,
     "end_time": "2022-03-13T16:01:08.391428",
     "exception": false,
     "start_time": "2022-03-13T16:01:08.376516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Credit\n",
    "\n",
    "This notebook is based on the following notebook by @yasufuminakama. I would like to take this opportunity to thank him.\n",
    "\n",
    "Please vote for his notebook as well.\n",
    "\n",
    "https://www.kaggle.com/yasufuminakama/cassava-resnext50-32x4d-starter-training\n",
    "\n",
    "# Summary of this notebook\n",
    "\n",
    "In this notebook, we are gonna build the nocall detector. (0:nocall, 1:somebird singing)\n",
    "\n",
    "The output of the models would be probability value.\n",
    "\n",
    "# input & output of this notebook\n",
    "\n",
    "[input]\n",
    "\n",
    "freefield1010 data\n",
    "\n",
    "https://www.kaggle.com/startjapan/ff1010bird-duration7\n",
    "\n",
    "[output]\n",
    "\n",
    "Nocall detector models are outputted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1194a20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:08.425435Z",
     "iopub.status.busy": "2022-03-13T16:01:08.423890Z",
     "iopub.status.idle": "2022-03-13T16:01:08.432991Z",
     "shell.execute_reply": "2022-03-13T16:01:08.433374Z",
     "shell.execute_reply.started": "2022-03-13T15:44:37.883818Z"
    },
    "papermill": {
     "duration": 0.026872,
     "end_time": "2022-03-13T16:01:08.433588",
     "exception": false,
     "start_time": "2022-03-13T16:01:08.406716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f7d216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:08.466150Z",
     "iopub.status.busy": "2022-03-13T16:01:08.465449Z",
     "iopub.status.idle": "2022-03-13T16:01:10.002373Z",
     "shell.execute_reply": "2022-03-13T16:01:10.001739Z",
     "shell.execute_reply.started": "2022-03-13T15:44:37.898764Z"
    },
    "papermill": {
     "duration": 1.555347,
     "end_time": "2022-03-13T16:01:10.002517",
     "exception": false,
     "start_time": "2022-03-13T16:01:08.447170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CFG:\n",
    "    print_freq=100\n",
    "    num_workers=4\n",
    "    model_name= 'resnext50_32x4d'\n",
    "    dim=(128, 281)\n",
    "    scheduler='CosineAnnealingWarmRestarts'\n",
    "    epochs=10\n",
    "    lr=1e-4\n",
    "    T_0=10 # for CosineAnnealingWarmRestarts\n",
    "    min_lr=5e-7 # for CosineAnnealingWarmRestarts\n",
    "    batch_size=32\n",
    "    weight_decay=1e-6\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=2\n",
    "    target_col='hasbird'\n",
    "    n_fold = 5\n",
    "    pretrained = True\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99feedc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:10.033966Z",
     "iopub.status.busy": "2022-03-13T16:01:10.033251Z",
     "iopub.status.idle": "2022-03-13T16:01:18.540055Z",
     "shell.execute_reply": "2022-03-13T16:01:18.539550Z",
     "shell.execute_reply.started": "2022-03-13T15:44:37.921505Z"
    },
    "papermill": {
     "duration": 8.523873,
     "end_time": "2022-03-13T16:01:18.540194",
     "exception": false,
     "start_time": "2022-03-13T16:01:10.016321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.5.1)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (3.0.6)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (21.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (8.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.20.3)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (4.28.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629aec91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:18.578225Z",
     "iopub.status.busy": "2022-03-13T16:01:18.577541Z",
     "iopub.status.idle": "2022-03-13T16:01:19.429843Z",
     "shell.execute_reply": "2022-03-13T16:01:19.430279Z",
     "shell.execute_reply.started": "2022-03-13T15:44:48.322208Z"
    },
    "papermill": {
     "duration": 0.874998,
     "end_time": "2022-03-13T16:01:19.430428",
     "exception": false,
     "start_time": "2022-03-13T16:01:18.555430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  hasbird\n",
      "0     0          1151\n",
      "      1           387\n",
      "1     0          1151\n",
      "      1           387\n",
      "2     0          1151\n",
      "      1           387\n",
      "3     0          1151\n",
      "      1           387\n",
      "4     0          1151\n",
      "      1           387\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../input/ff1010bird-duration7/rich_metadata.csv')\n",
    "train.loc[train['hasbird']==0, 'filepath'] = '../input/ff1010bird-duration7/nocall/' + train.query('hasbird==0')['filename'] + '.npy'\n",
    "train.loc[train['hasbird']==1, 'filepath'] = '../input/ff1010bird-duration7/bird/' + train.query('hasbird==1')['filename'] + '.npy'\n",
    "\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "folds = train.copy()\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col])):\n",
    "    folds.loc[val_index, 'fold'] = int(n)\n",
    "folds['fold'] = folds['fold'].astype(int)\n",
    "print(folds.groupby(['fold', CFG.target_col]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131c5f48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:19.470985Z",
     "iopub.status.busy": "2022-03-13T16:01:19.470369Z",
     "iopub.status.idle": "2022-03-13T16:01:30.551922Z",
     "shell.execute_reply": "2022-03-13T16:01:30.551386Z",
     "shell.execute_reply.started": "2022-03-13T15:44:48.396042Z"
    },
    "papermill": {
     "duration": 11.106918,
     "end_time": "2022-03-13T16:01:30.552057",
     "exception": false,
     "start_time": "2022-03-13T16:01:19.445139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\r\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\r\n",
      "     |████████████████████████████████| 431 kB 763 kB/s            \r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.10.1)\r\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.9.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.1.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.20.3)\r\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (8.2.0)\r\n",
      "Installing collected packages: timm\r\n",
      "Successfully installed timm-0.5.4\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "!pip install timm\n",
    "import timm\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c92c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.598566Z",
     "iopub.status.busy": "2022-03-13T16:01:30.596712Z",
     "iopub.status.idle": "2022-03-13T16:01:30.603578Z",
     "shell.execute_reply": "2022-03-13T16:01:30.603990Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.432316Z"
    },
    "papermill": {
     "duration": 0.033251,
     "end_time": "2022-03-13T16:01:30.604125",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.570874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_score(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def get_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957202e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.647813Z",
     "iopub.status.busy": "2022-03-13T16:01:30.647060Z",
     "iopub.status.idle": "2022-03-13T16:01:30.649027Z",
     "shell.execute_reply": "2022-03-13T16:01:30.649486Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.452845Z"
    },
    "papermill": {
     "duration": 0.027707,
     "end_time": "2022-03-13T16:01:30.649606",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.621899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['filepath'].values\n",
    "        self.labels = df['hasbird'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_paths[idx]\n",
    "        file_path = file_name\n",
    "        image = np.load(file_path)\n",
    "        image = image.transpose(1,2,0)\n",
    "        image = np.squeeze(image)\n",
    "        image = np.stack((image,)*3, -1)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        label = torch.tensor(self.labels[idx]).long()\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e67d64e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.692520Z",
     "iopub.status.busy": "2022-03-13T16:01:30.691715Z",
     "iopub.status.idle": "2022-03-13T16:01:30.694179Z",
     "shell.execute_reply": "2022-03-13T16:01:30.693645Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.467189Z"
    },
    "papermill": {
     "duration": 0.027043,
     "end_time": "2022-03-13T16:01:30.694302",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.667259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.augmentations.transforms.JpegCompression(p=0.5),\n",
    "            A.augmentations.transforms.ImageCompression(p=0.5, compression_type=A.augmentations.transforms.ImageCompression.ImageCompressionType.WEBP),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return A.Compose([\n",
    "            A.Resize(CFG.dim[0], CFG.dim[1]),\n",
    "            A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74af4e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.732049Z",
     "iopub.status.busy": "2022-03-13T16:01:30.731263Z",
     "iopub.status.idle": "2022-03-13T16:01:30.736443Z",
     "shell.execute_reply": "2022-03-13T16:01:30.736829Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.483885Z"
    },
    "papermill": {
     "duration": 0.025179,
     "end_time": "2022-03-13T16:01:30.736952",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.711773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_name='resnext50_32x4d', pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, CFG.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d69c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.796828Z",
     "iopub.status.busy": "2022-03-13T16:01:30.781287Z",
     "iopub.status.idle": "2022-03-13T16:01:30.800606Z",
     "shell.execute_reply": "2022-03-13T16:01:30.801028Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.500420Z"
    },
    "papermill": {
     "duration": 0.046294,
     "end_time": "2022-03-13T16:01:30.801156",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.754862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  .format(\n",
    "                   epoch+1, step+1, len(train_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                   grad_norm=grad_norm,\n",
    "                   ))\n",
    "    return losses.avg\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    # switch to evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(\n",
    "                   step+1, len(valid_loader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses,\n",
    "                   remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                   ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "\n",
    "def inference(model, states, test_loader, device):\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    probs = []\n",
    "    for i, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        avg_preds = []\n",
    "        for state in states:\n",
    "            model.load_state_dict(state['model'])\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(images)\n",
    "            avg_preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        avg_preds = np.mean(avg_preds, axis=0)\n",
    "        probs.append(avg_preds)\n",
    "    probs = np.concatenate(probs)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0160339a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.850395Z",
     "iopub.status.busy": "2022-03-13T16:01:30.849622Z",
     "iopub.status.idle": "2022-03-13T16:01:30.851951Z",
     "shell.execute_reply": "2022-03-13T16:01:30.851516Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.535800Z"
    },
    "papermill": {
     "duration": 0.033302,
     "end_time": "2022-03-13T16:01:30.852061",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.818759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop(train_folds, valid_folds):\n",
    "\n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    train_dataset = TrainDataset(train_folds, \n",
    "                                 transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, \n",
    "                                 transform=get_transforms(data='valid'))\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    def get_scheduler(optimizer):\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomResNext(CFG.model_name, pretrained=True)\n",
    "    model.to(CFG.device)\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_score = 0.\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for epoch in range(CFG.epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, CFG.device)\n",
    "        \n",
    "        # eval\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, CFG.device)\n",
    "        valid_labels = valid_folds[CFG.target_col].values\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_score(valid_labels, preds.argmax(1))\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Accuracy: {score}')\n",
    "        \n",
    "        scores.append(score)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    \n",
    "    check_point = torch.load(OUTPUT_DIR+f'{CFG.model_name}_best.pth')\n",
    "    valid_folds[[str(c) for c in range(CFG.target_size)]] = check_point['preds']\n",
    "    valid_folds['preds'] = check_point['preds'].argmax(1)\n",
    "\n",
    "    return valid_folds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4be37167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.895700Z",
     "iopub.status.busy": "2022-03-13T16:01:30.895007Z",
     "iopub.status.idle": "2022-03-13T16:01:30.897514Z",
     "shell.execute_reply": "2022-03-13T16:01:30.897124Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.558795Z"
    },
    "papermill": {
     "duration": 0.028206,
     "end_time": "2022-03-13T16:01:30.897617",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.869411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(fold):\n",
    "    def get_result(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.5f}')\n",
    "    \n",
    "    def get_result2(result_df):\n",
    "        preds = result_df['preds'].values\n",
    "        labels = result_df[CFG.target_col].values\n",
    "        matrix = get_confusion_matrix(labels, preds)\n",
    "        print('TN', matrix[0,0])\n",
    "        print('FP', matrix[0,1])\n",
    "        print('FN', matrix[1,0])\n",
    "        print('TP', matrix[1,1])\n",
    "    \n",
    "    # train \n",
    "    train_folds = folds.query(f'fold!={fold}').reset_index(drop=True)\n",
    "    valid_folds = folds.query(f'fold=={fold}').reset_index(drop=False)\n",
    "    oof_df, scores = train_loop(train_folds, valid_folds)\n",
    "    # CV result\n",
    "    LOGGER.info(f\"========== CV ==========\")\n",
    "    get_result(oof_df)\n",
    "    get_result2(oof_df)\n",
    "    # save result\n",
    "    oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    plt.plot([i for i in range(CFG.epochs)], scores)\n",
    "    plt.title('valid score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1faf1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-13T16:01:30.936531Z",
     "iopub.status.busy": "2022-03-13T16:01:30.935721Z",
     "iopub.status.idle": "2022-03-13T16:12:32.449631Z",
     "shell.execute_reply": "2022-03-13T16:12:32.450059Z",
     "shell.execute_reply.started": "2022-03-13T15:45:00.575699Z"
    },
    "papermill": {
     "duration": 661.535259,
     "end_time": "2022-03-13T16:12:32.450215",
     "exception": false,
     "start_time": "2022-03-13T16:01:30.914956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== training ==========\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnext50_32x4d_a1h-0146ab0a.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d_a1h-0146ab0a.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][1/192] Data 0.983 (0.983) Elapsed 0m 7s (remain 24m 54s) Loss: 0.6861(0.6861) Grad: 44.5738  \n",
      "Epoch: [1][101/192] Data 0.000 (0.010) Elapsed 0m 38s (remain 0m 35s) Loss: 0.3485(0.5323) Grad: 17.9507  \n",
      "Epoch: [1][192/192] Data 0.000 (0.006) Elapsed 1m 6s (remain 0m 0s) Loss: 0.5620(0.4709) Grad: 29.5258  \n",
      "EVAL: [1/49] Data 0.512 (0.512) Elapsed 0m 0s (remain 0m 28s) Loss: 0.3582(0.3582) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - avg_train_loss: 0.4709  avg_val_loss: 0.3804  time: 73s\n",
      "Epoch 1 - Accuracy: 0.8556566970091027\n",
      "Epoch 1 - Save Best Score: 0.8557 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.043) Elapsed 0m 5s (remain 0m 0s) Loss: 0.3406(0.3804) \n",
      "Epoch: [2][1/192] Data 0.866 (0.866) Elapsed 0m 1s (remain 3m 49s) Loss: 0.3337(0.3337) Grad: 16.2094  \n",
      "Epoch: [2][101/192] Data 0.002 (0.009) Elapsed 0m 32s (remain 0m 28s) Loss: 0.2844(0.3516) Grad: 15.1736  \n",
      "Epoch: [2][192/192] Data 0.000 (0.005) Elapsed 1m 0s (remain 0m 0s) Loss: 0.4658(0.3365) Grad: 19.8805  \n",
      "EVAL: [1/49] Data 0.337 (0.337) Elapsed 0m 0s (remain 0m 19s) Loss: 0.3556(0.3556) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - avg_train_loss: 0.3365  avg_val_loss: 0.3582  time: 64s\n",
      "Epoch 2 - Accuracy: 0.8693107932379714\n",
      "Epoch 2 - Save Best Score: 0.8693 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.3962(0.3582) \n",
      "Epoch: [3][1/192] Data 0.827 (0.827) Elapsed 0m 1s (remain 3m 47s) Loss: 0.2753(0.2753) Grad: 11.7961  \n",
      "Epoch: [3][101/192] Data 0.000 (0.009) Elapsed 0m 31s (remain 0m 28s) Loss: 0.2417(0.3088) Grad: 15.9372  \n",
      "Epoch: [3][192/192] Data 0.000 (0.005) Elapsed 1m 0s (remain 0m 0s) Loss: 0.3662(0.2942) Grad: 15.6829  \n",
      "EVAL: [1/49] Data 0.348 (0.348) Elapsed 0m 0s (remain 0m 20s) Loss: 0.4542(0.4542) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - avg_train_loss: 0.2942  avg_val_loss: 0.3339  time: 64s\n",
      "Epoch 3 - Accuracy: 0.8797139141742523\n",
      "Epoch 3 - Save Best Score: 0.8797 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.4881(0.3339) \n",
      "Epoch: [4][1/192] Data 0.997 (0.997) Elapsed 0m 1s (remain 4m 27s) Loss: 0.1697(0.1697) Grad: 10.6706  \n",
      "Epoch: [4][101/192] Data 0.000 (0.011) Elapsed 0m 32s (remain 0m 29s) Loss: 0.1707(0.2812) Grad: 9.2352  \n",
      "Epoch: [4][192/192] Data 0.000 (0.006) Elapsed 1m 0s (remain 0m 0s) Loss: 0.2922(0.2683) Grad: 15.6587  \n",
      "EVAL: [1/49] Data 0.310 (0.310) Elapsed 0m 0s (remain 0m 18s) Loss: 0.4465(0.4465) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 - avg_train_loss: 0.2683  avg_val_loss: 0.3311  time: 65s\n",
      "Epoch 4 - Accuracy: 0.881664499349805\n",
      "Epoch 4 - Save Best Score: 0.8817 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.007) Elapsed 0m 4s (remain 0m 0s) Loss: 0.5454(0.3311) \n",
      "Epoch: [5][1/192] Data 0.966 (0.966) Elapsed 0m 1s (remain 4m 12s) Loss: 0.1728(0.1728) Grad: 11.1087  \n",
      "Epoch: [5][101/192] Data 0.001 (0.010) Elapsed 0m 32s (remain 0m 29s) Loss: 0.1925(0.2457) Grad: 13.3564  \n",
      "Epoch: [5][192/192] Data 0.000 (0.006) Elapsed 1m 0s (remain 0m 0s) Loss: 0.2789(0.2328) Grad: 16.7715  \n",
      "EVAL: [1/49] Data 0.389 (0.389) Elapsed 0m 0s (remain 0m 22s) Loss: 0.4162(0.4162) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 - avg_train_loss: 0.2328  avg_val_loss: 0.3323  time: 65s\n",
      "Epoch 5 - Accuracy: 0.8823146944083224\n",
      "Epoch 5 - Save Best Score: 0.8823 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.009) Elapsed 0m 4s (remain 0m 0s) Loss: 0.4877(0.3323) \n",
      "Epoch: [6][1/192] Data 0.896 (0.896) Elapsed 0m 1s (remain 3m 57s) Loss: 0.2418(0.2418) Grad: 11.7232  \n",
      "Epoch: [6][101/192] Data 0.000 (0.010) Elapsed 0m 32s (remain 0m 28s) Loss: 0.1245(0.2152) Grad: 8.9393  \n",
      "Epoch: [6][192/192] Data 0.000 (0.005) Elapsed 1m 0s (remain 0m 0s) Loss: 0.2430(0.2015) Grad: 13.7379  \n",
      "EVAL: [1/49] Data 0.313 (0.313) Elapsed 0m 0s (remain 0m 19s) Loss: 0.4529(0.4529) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 - avg_train_loss: 0.2015  avg_val_loss: 0.3578  time: 64s\n",
      "Epoch 6 - Accuracy: 0.8849154746423927\n",
      "Epoch 6 - Save Best Score: 0.8849 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.007) Elapsed 0m 4s (remain 0m 0s) Loss: 0.6891(0.3578) \n",
      "Epoch: [7][1/192] Data 0.837 (0.837) Elapsed 0m 1s (remain 3m 43s) Loss: 0.1378(0.1378) Grad: 14.1288  \n",
      "Epoch: [7][101/192] Data 0.000 (0.009) Elapsed 0m 32s (remain 0m 29s) Loss: 0.0856(0.1924) Grad: 8.5511  \n",
      "Epoch: [7][192/192] Data 0.000 (0.005) Elapsed 1m 0s (remain 0m 0s) Loss: 0.2248(0.1757) Grad: 14.3300  \n",
      "EVAL: [1/49] Data 0.339 (0.339) Elapsed 0m 0s (remain 0m 20s) Loss: 0.4822(0.4822) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 - avg_train_loss: 0.1757  avg_val_loss: 0.3496  time: 64s\n",
      "Epoch 7 - Accuracy: 0.88296488946684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.6277(0.3496) \n",
      "Epoch: [8][1/192] Data 0.894 (0.894) Elapsed 0m 1s (remain 3m 54s) Loss: 0.1445(0.1445) Grad: 12.2100  \n",
      "Epoch: [8][101/192] Data 0.000 (0.009) Elapsed 0m 31s (remain 0m 28s) Loss: 0.1504(0.1690) Grad: 11.8613  \n",
      "Epoch: [8][192/192] Data 0.000 (0.005) Elapsed 0m 59s (remain 0m 0s) Loss: 0.2302(0.1527) Grad: 14.9345  \n",
      "EVAL: [1/49] Data 0.370 (0.370) Elapsed 0m 0s (remain 0m 21s) Loss: 0.5256(0.5256) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 - avg_train_loss: 0.1527  avg_val_loss: 0.3492  time: 64s\n",
      "Epoch 8 - Accuracy: 0.8894668400520156\n",
      "Epoch 8 - Save Best Score: 0.8895 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.6197(0.3492) \n",
      "Epoch: [9][1/192] Data 0.647 (0.647) Elapsed 0m 0s (remain 3m 9s) Loss: 0.1414(0.1414) Grad: 20.5579  \n",
      "Epoch: [9][101/192] Data 0.001 (0.007) Elapsed 0m 32s (remain 0m 28s) Loss: 0.1206(0.1514) Grad: 12.5111  \n",
      "Epoch: [9][192/192] Data 0.000 (0.004) Elapsed 0m 59s (remain 0m 0s) Loss: 0.1412(0.1360) Grad: 14.3256  \n",
      "EVAL: [1/49] Data 0.361 (0.361) Elapsed 0m 0s (remain 0m 21s) Loss: 0.5584(0.5584) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 - avg_train_loss: 0.1360  avg_val_loss: 0.3487  time: 64s\n",
      "Epoch 9 - Accuracy: 0.8875162548764629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.5071(0.3487) \n",
      "Epoch: [10][1/192] Data 0.932 (0.932) Elapsed 0m 1s (remain 4m 11s) Loss: 0.1060(0.1060) Grad: 7.7375  \n",
      "Epoch: [10][101/192] Data 0.001 (0.010) Elapsed 0m 32s (remain 0m 28s) Loss: 0.0695(0.1501) Grad: 8.8940  \n",
      "Epoch: [10][192/192] Data 0.000 (0.006) Elapsed 0m 59s (remain 0m 0s) Loss: 0.2336(0.1335) Grad: 16.8564  \n",
      "EVAL: [1/49] Data 0.377 (0.377) Elapsed 0m 0s (remain 0m 21s) Loss: 0.5625(0.5625) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 - avg_train_loss: 0.1335  avg_val_loss: 0.3506  time: 64s\n",
      "Epoch 10 - Accuracy: 0.8855656697009102\n",
      "========== CV ==========\n",
      "Score: 0.88947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [49/49] Data 0.000 (0.008) Elapsed 0m 4s (remain 0m 0s) Loss: 0.4102(0.3506) \n",
      "TN 1120\n",
      "FP 31\n",
      "FN 139\n",
      "TP 248\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7096410",
   "metadata": {
    "papermill": {
     "duration": 0.054822,
     "end_time": "2022-03-13T16:12:32.547879",
     "exception": false,
     "start_time": "2022-03-13T16:12:32.493057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 694.582854,
   "end_time": "2022-03-13T16:12:35.208428",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-13T16:01:00.625574",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
